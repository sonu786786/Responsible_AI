{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHOBAjyEgDH+xIkx6OjBSW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonu786786/Responsible_AI/blob/main/Lab_04/quest1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n5wByo9diib0",
        "outputId": "0f0fd126-94ce-4cfa-d38a-67d969e2ffed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_API_TOKEN\"] = \"KGAT_155b95a19a48a3e19bfe45f85966a4a0\"\n"
      ],
      "metadata": {
        "id": "5hIzA6jPjISL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"ryanbadai/clothes-dataset\")\n",
        "print(\"Dataset path:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DKFN9i3ljjUQ",
        "outputId": "3975b28b-5e67-4345-d91a-845b76db696c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ryanbadai/clothes-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.37G/1.37G [01:04<00:00, 22.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /root/.cache/kagglehub/datasets/ryanbadai/clothes-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4Xr_xxWjobR",
        "outputId": "12329864-e16e-4d35-aefb-e41145b55f62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clothes_Dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.path.join(path, \"Clothes_Dataset\")\n",
        "os.listdir(dataset_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q95pAUvNj5FB",
        "outputId": "13941e6a-e1e6-4a58-fab3-706b4b24b695"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Celana_Pendek',\n",
              " 'Jeans',\n",
              " 'Rok',\n",
              " 'Gaun',\n",
              " 'Kaos',\n",
              " 'Sweter',\n",
              " 'Jaket',\n",
              " 'Hoodie',\n",
              " 'Jaket_Denim',\n",
              " 'Celana_Panjang',\n",
              " 'Polo',\n",
              " 'Blazer',\n",
              " 'Kemeja',\n",
              " 'Jaket_Olahraga',\n",
              " 'Mantel']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in os.listdir(dataset_path):\n",
        "   print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQEKnk5EV-X6",
        "outputId": "01b97ee0-0822-4179-c073-1b851a1a66f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Celana_Pendek\n",
            "Jeans\n",
            "Rok\n",
            "Gaun\n",
            "Kaos\n",
            "Sweter\n",
            "Jaket\n",
            "Hoodie\n",
            "Jaket_Denim\n",
            "Celana_Panjang\n",
            "Polo\n",
            "Blazer\n",
            "Kemeja\n",
            "Jaket_Olahraga\n",
            "Mantel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "N5C_OaANXkiE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                         std=[0.5, 0.5, 0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "XQg7vqNDY1s7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Total Images:\", len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTZ6DVJ1ZO5U",
        "outputId": "5e5a8d96-5a66-4cb9-e81d-a2a6ad875060"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Blazer', 'Celana_Panjang', 'Celana_Pendek', 'Gaun', 'Hoodie', 'Jaket', 'Jaket_Denim', 'Jaket_Olahraga', 'Jeans', 'Kaos', 'Kemeja', 'Mantel', 'Polo', 'Rok', 'Sweter']\n",
            "Total Images: 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "gR-l_1f1Zjoe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ZmLAT0MWZ1QS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB27eAoiaYVw",
        "outputId": "06b91677-f749-4a21-95f1-7cb2216d941f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Model(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN_Model, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 16 * 16, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BxFQ5RJ5apdi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_Model(num_classes=len(dataset.classes)).to(device)"
      ],
      "metadata": {
        "id": "EVY9mFCZbNim"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "-oCypoWkb90n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "        evaluate(model, val_loader)\n"
      ],
      "metadata": {
        "id": "mcv2YFG7cX8X"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "pzN70sUYdiag"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRbePaagfc6y",
        "outputId": "7e6a0aee-59ac-4b75-f202-d4a29b5b587e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.2306\n",
            "Validation Accuracy: 41.20%\n",
            "Epoch [2/10], Loss: 1.5745\n",
            "Validation Accuracy: 47.13%\n",
            "Epoch [3/10], Loss: 1.1666\n",
            "Validation Accuracy: 52.07%\n",
            "Epoch [4/10], Loss: 0.7568\n",
            "Validation Accuracy: 51.67%\n",
            "Epoch [5/10], Loss: 0.3943\n",
            "Validation Accuracy: 53.13%\n",
            "Epoch [6/10], Loss: 0.1935\n",
            "Validation Accuracy: 51.67%\n",
            "Epoch [7/10], Loss: 0.1145\n",
            "Validation Accuracy: 51.87%\n",
            "Epoch [8/10], Loss: 0.0819\n",
            "Validation Accuracy: 50.67%\n",
            "Epoch [9/10], Loss: 0.0827\n",
            "Validation Accuracy: 50.47%\n",
            "Epoch [10/10], Loss: 0.0537\n",
            "Validation Accuracy: 52.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_model = Smaller_CNN(num_classes=len(dataset.classes)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(small_model.parameters(), lr=0.001)\n",
        "\n",
        "train_model(small_model, train_loader, val_loader, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9_t4zEfqMO",
        "outputId": "000c64ea-7324-473c-f70c-0bd9c5cc4e3d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.2522\n",
            "Validation Accuracy: 40.93%\n",
            "Epoch [2/10], Loss: 1.5018\n",
            "Validation Accuracy: 44.67%\n",
            "Epoch [3/10], Loss: 1.0074\n",
            "Validation Accuracy: 47.53%\n",
            "Epoch [4/10], Loss: 0.5697\n",
            "Validation Accuracy: 48.47%\n",
            "Epoch [5/10], Loss: 0.2528\n",
            "Validation Accuracy: 48.00%\n",
            "Epoch [6/10], Loss: 0.1393\n",
            "Validation Accuracy: 47.60%\n",
            "Epoch [7/10], Loss: 0.0831\n",
            "Validation Accuracy: 47.27%\n",
            "Epoch [8/10], Loss: 0.0594\n",
            "Validation Accuracy: 49.93%\n",
            "Epoch [9/10], Loss: 0.0519\n",
            "Validation Accuracy: 47.60%\n",
            "Epoch [10/10], Loss: 0.0450\n",
            "Validation Accuracy: 49.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model       | Conv Layers | Best Val Accuracy | Final Training Loss | Observation                                       |\n",
        "| ----------- | ----------- | ----------------- | ------------------- | ------------------------------------------------- |\n",
        "| Full CNN    | 3           | 53.13%            | 0.0537              | Better accuracy, overfitting observed             |\n",
        "| Reduced CNN | 2           | 49.93%            | 0.0450              | Lower accuracy, reduced feature learning capacity |\n"
      ],
      "metadata": {
        "id": "DNh5d6YMIGE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Conclusion\n",
        "\n",
        "A CNN model with three convolution layers achieved a maximum validation accuracy of approximately 53.13%. However, the training loss reduced significantly to near zero, indicating overfitting.\n",
        "\n",
        "After decreasing the number of convolution layers to two, the validation accuracy dropped to approximately 49.93%. This demonstrates that reducing the number of convolution layers decreases the model’s ability to extract complex hierarchical features from images.\n",
        "\n",
        "The deeper CNN performed better due to increased representational capacity, while the shallower CNN had limited feature abstraction capability. Therefore, decreasing the number of convolution layers negatively impacted model performance."
      ],
      "metadata": {
        "id": "e37HqEXqIOTN"
      }
    }
  ]
}